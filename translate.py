#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# @Time : 2025/8/10
# @Author : julong@111.com
# @Description : JuSubTitleAutoTranslate - SRTå­—å¹•æ–‡ä»¶AIè‡ªåŠ¨ç¿»è¯‘è„šæœ¬
#   æ”¯æŒ Helsinki-NLP/opus-mt-en-zhï¼ˆé€Ÿåº¦å¿«ï¼‰å’Œfacebook/nllb-200-distilled-600Mï¼ˆè´¨é‡é«˜ï¼‰ä¸¤ç§æ¨¡å‹

import argparse
import sys
import time
import logging
from pathlib import Path
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
from srt_utils import (
    parse_srt_file, 
    write_srt_file, 
    clean_text, 
    validate_srt_file,
    get_output_filename
)

MODEL_MAP = {
    "opus": "Helsinki-NLP/opus-mt-en-zh",
    "nllb": "facebook/nllb-200-distilled-600M"
}

def load_model(model_type: str, model_path: str = None, auto_download: bool = False):
    """
    é€šç”¨æ¨¡å‹åŠ è½½å‡½æ•°ï¼Œæ”¯æŒopuså’Œnllbã€‚
    model_type: "opus" æˆ– "nllb"
    model_path: æœ¬åœ°æ¨¡å‹è·¯å¾„æˆ–ä¸‹è½½ç›®å½•
    auto_download: æ˜¯å¦è‡ªåŠ¨ä¸‹è½½
    """
    model_name = MODEL_MAP.get(model_type)
    if not model_name:
        raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_type}")
    try:
        if auto_download or not model_path:
            # ä¸‹è½½åˆ°æŒ‡å®šç›®å½•æˆ–é»˜è®¤ç¼“å­˜
            cache_dir = model_path if model_path else None
            logging.info(f"ğŸ”„ æ­£åœ¨è‡ªåŠ¨ä¸‹è½½æ¨¡å‹ {model_name} åˆ° {cache_dir or 'é»˜è®¤ç¼“å­˜ç›®å½•'}")
            tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=cache_dir)
            model = AutoModelForSeq2SeqLM.from_pretrained(model_name, cache_dir=cache_dir)
        else:
            # åŠ è½½æœ¬åœ°æ¨¡å‹
            logging.info(f"ğŸ”’ æ­£åœ¨åŠ è½½æœ¬åœ°æ¨¡å‹ {model_path}")
            tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True)
            model = AutoModelForSeq2SeqLM.from_pretrained(model_path, local_files_only=True)
        logging.info(f"âœ… {model_type} æ¨¡å‹åŠ è½½æˆåŠŸ")
        return tokenizer, model
    except Exception as e:
        if auto_download:
            logging.info(f"âŒ æ¨¡å‹è‡ªåŠ¨ä¸‹è½½å¤±è´¥: {e}")
            logging.info("ğŸ’¡ è§£å†³æ–¹æ¡ˆï¼š")
            logging.info("1. æ£€æŸ¥ç½‘ç»œè¿æ¥å¹¶é‡è¯•")
            logging.info("2. æ‰‹å·¥ä¸‹è½½å¹¶æŒ‡å®šæ­£ç¡®çš„æ¨¡å‹è·¯å¾„")
        else:
            logging.info("âŒ æœ¬åœ°æ¨¡å‹åŠ è½½å¤±è´¥")
            logging.info("ğŸ’¡ è§£å†³æ–¹æ¡ˆï¼š")
            logging.info("1. ä½¿ç”¨ --auto-download å‚æ•°è‡ªåŠ¨ä¸‹è½½æ¨¡å‹")
            logging.info(f"2. ç¡®ä¿æ¨¡å‹è·¯å¾„æ­£ç¡® {model_path}")
            logging.info("3. æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹åˆ°æŒ‡å®šç›®å½•")
        raise

class TranslationModel:
    """ç¿»è¯‘æ¨¡å‹åŸºç±»"""

    def __init__(self, name: str):
        self.name = name
     
    def translate_text(self, text: str, tokenizer, model, **kwargs) -> str:
        """ç¿»è¯‘æ–‡æœ¬"""
        raise NotImplementedError

class OPUSMTModel(TranslationModel):
    """OPUS-MTæ¨¡å‹å®ç°"""
    
    def __init__(self):
        super().__init__(name="OPUS-MT") 

    def translate_text(self, text: str, tokenizer, model, max_length: int = 512) -> str:
        """ä½¿ç”¨OPUS-MTæ¨¡å‹ç¿»è¯‘æ–‡æœ¬"""
        try:
            clean_text_result = clean_text(text)
            
            if not clean_text_result.strip():
                return text
            
            inputs = tokenizer(clean_text_result, return_tensors="pt", padding=True, truncation=True, max_length=max_length)
            outputs = model.generate(**inputs)
            result = tokenizer.decode(outputs[0], skip_special_tokens=True)
            
            return result
        except Exception as e:
            logging.info(f"ç¿»è¯‘æ–‡æœ¬æ—¶å‡ºé”™: {e}")
            return text

class NLLBModel(TranslationModel):
    """NLLBæ¨¡å‹å®ç°"""
    
    def __init__(self):
        super().__init__(name="NLLB-200-distilled-600M")
    
    def translate_text(self, text: str, tokenizer, model, source_lang: str = "eng_Latn", 
                      target_lang: str = "zho_Hans", max_length: int = 512) -> str:
        """ä½¿ç”¨NLLBæ¨¡å‹ç¿»è¯‘æ–‡æœ¬"""
        try:
            clean_text_result = clean_text(text)
            
            if not clean_text_result.strip():
                return text
            
            # NLLBæ¨¡å‹éœ€è¦æŒ‡å®šæºè¯­è¨€å’Œç›®æ ‡è¯­è¨€
            input_text = f"{source_lang} {clean_text_result}"
            
            inputs = tokenizer(input_text, return_tensors="pt", padding=True, truncation=True, max_length=max_length)
            # outputs = model.generate(**inputs, forced_bos_token_id=tokenizer.lang_code_to_id[target_lang])
            outputs = model.generate(**inputs, forced_bos_token_id=tokenizer.convert_tokens_to_ids(target_lang))
            result = tokenizer.decode(outputs[0], skip_special_tokens=True)
            
            return result
        except Exception as e:
            logging.info(f"ç¿»è¯‘æ–‡æœ¬æ—¶å‡ºé”™: {e}")
            return text

def get_model_class(model_type: str) -> TranslationModel:
    """æ ¹æ®æ¨¡å‹ç±»å‹è·å–å¯¹åº”çš„æ¨¡å‹ç±»"""
    model_map = {
        'opus': OPUSMTModel,
        'nllb': NLLBModel
    }
    
    model_type_lower = model_type.lower()
    for key, model_class in model_map.items():
        if key in model_type_lower:
            return model_class()
    
    raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_type}ã€‚æ”¯æŒçš„ç±»å‹: opus, nllb")

def translate_subtitles(subtitles: list, model_instance: TranslationModel, 
                       tokenizer, model, **kwargs) -> tuple:
    """ç¿»è¯‘å­—å¹•åˆ—è¡¨"""
    logging.info(f"ğŸŒ æ­£åœ¨ä½¿ç”¨{model_instance.name}æ¨¡å‹ç¿»è¯‘å­—å¹•...")
    
    translated_count = 0
    start_time = time.time()
    
    for i, subtitle in enumerate(subtitles):
        logging.info(f"ç¿»è¯‘è¿›åº¦: {i+1}/{len(subtitles)}")
        
        # ç¿»è¯‘æ–‡æœ¬
        translated_text = model_instance.translate_text(subtitle['text'], tokenizer, model, **kwargs)
        subtitle['text'] = translated_text
        translated_count += 1
    
    end_time = time.time()
    elapsed_time = end_time - start_time
    
    logging.info(f"\nâœ… ç¿»è¯‘å®Œæˆï¼Œå…±ç¿»è¯‘ {translated_count} æ¡å­—å¹•")
    logging.info(f"â±ï¸  æ€»è€—æ—¶: {elapsed_time:.2f} ç§’")
    logging.info(f"ğŸš€ å¹³å‡é€Ÿåº¦: {len(subtitles)/elapsed_time:.2f} æ¡/ç§’")
    
    return translated_count, elapsed_time

def main():
    parser = argparse.ArgumentParser(
        description='JuSubTrans - ç»Ÿä¸€SRTå­—å¹•æ–‡ä»¶AIè‡ªåŠ¨ç¿»è¯‘è„šæœ¬',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # ä½¿ç”¨OPUS-MTæ¨¡å‹ï¼ˆé€Ÿåº¦å¿«ï¼‰   é»˜è®¤æ¨¡å‹
  python translate.py -i input.srt
  
  # ä½¿ç”¨NLLBæ¨¡å‹ï¼ˆè´¨é‡é«˜ï¼‰
  python translate.py -i input.srt -m nllb
  
  # æŒ‡å®šæ¨¡å‹è·¯å¾„
  python translate.py -i input.srt -m opus --modelpath /path/to/model
  
  # è‡ªåŠ¨ä¸‹è½½æ¨¡å‹   åŒæ—¶æŒ‡å®šä¸‹è½½ä½ç½®ï¼ˆéå¿…å¡«ï¼‰
  python translate.py -i input.srt -m nllb --auto-download --modelpath /path/to/model
        """
    )
    
    parser.add_argument('-i','--input_file', required=True, help='è¾“å…¥çš„SRTæ–‡ä»¶è·¯å¾„')
    parser.add_argument('-o', '--output', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤åœ¨åŸæ–‡ä»¶åååŠ æ¨¡å‹æ ‡è¯†.zh-CNï¼‰')
    parser.add_argument('-m', '--model', choices=['opus', 'nllb'], default='opus',
                       help='é€‰æ‹©ç¿»è¯‘æ¨¡å‹: opus(é€Ÿåº¦å¿«) æˆ– nllb(è´¨é‡é«˜) [é»˜è®¤: opus]')
    parser.add_argument('--modelpath', 
                       help='æ¨¡å‹è·¯å¾„ï¼ˆå¯é€‰ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„ï¼‰')
    parser.add_argument('--auto-download', default=False, action='store_true',
                       help='å¦‚æœæœ¬åœ°æ¨¡å‹ä¸å­˜åœ¨ï¼Œè‡ªåŠ¨ä»Hugging Faceä¸‹è½½ï¼ˆé»˜è®¤ï¼šå¦ï¼‰')
    parser.add_argument('--source_lang', default='eng_Latn', 
                       help='æºè¯­è¨€ä»£ç ï¼ˆä»…NLLBæ¨¡å‹æœ‰æ•ˆï¼Œé»˜è®¤ï¼šeng_Latn è‹±æ–‡ï¼‰')
    parser.add_argument('--target_lang', default='zho_Hans', 
                       help='ç›®æ ‡è¯­è¨€ä»£ç ï¼ˆä»…NLLBæ¨¡å‹æœ‰æ•ˆï¼Œé»˜è®¤ï¼šzho_Hans ç®€ä½“ä¸­æ–‡ï¼‰')
    parser.add_argument('--max-length', type=int, default=512,
                       help='æœ€å¤§è¾“å…¥é•¿åº¦ï¼ˆé»˜è®¤ï¼š512ï¼‰')
    
    args = parser.parse_args()
    logging.debug(f"DEBUG: args = {args}")
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    input_path = Path(args.input_file)
    if not validate_srt_file(input_path):
        logging.info(f"âŒ é”™è¯¯ï¼šè¾“å…¥æ–‡ä»¶æ— æ•ˆæˆ–ä¸æ˜¯SRTæ ¼å¼: {input_path}")
        sys.exit(1)
    
    # è·å–æ¨¡å‹å®ä¾‹
    try:
        model_instance = get_model_class(args.model)
    except ValueError as e:
        logging.info(f"âŒ é”™è¯¯ï¼š{e}")
        sys.exit(1)
    nomodelpath = False
    # è®¾ç½®é»˜è®¤æ¨¡å‹è·¯å¾„
    if not args.modelpath:
        nomodelpath = True
        if args.model == 'opus':
            args.modelpath = './models/models--Helsinki-NLP--opus-mt-en-zh/snapshots/408d9bc410a388e1d9aef112a2daba955b945255'
        else:  # nllb
            args.modelpath = './models/models--facebook--nllb-200-distilled-600M/snapshots/f8d333a098d19b4fd9a8b18f94170487ad3f821d' 
    
    # è®¾ç½®è¾“å‡ºæ–‡ä»¶è·¯å¾„
    if args.output:
        output_path = Path(args.output)
    else:
        suffix = f"_{args.model}_translated.zh-CN"
        output_path = get_output_filename(input_path, suffix)
    
    logging.info("ğŸ¯ JuSubTitleAutoTranslate - å­—å¹•ç¿»è¯‘å·¥å…·")
    logging.info(f"ğŸ“ è¾“å…¥æ–‡ä»¶: {input_path}")
    logging.info(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_path}")
    logging.info(f"ğŸ¤– æ¨¡å‹: {model_instance.name}")
    logging.info(f"ğŸ“‚ æ¨¡å‹è·¯å¾„: {args.modelpath}")
    logging.info(f"â¬‡ï¸  è‡ªåŠ¨ä¸‹è½½: {'æ˜¯' if args.auto_download else 'å¦'}")
    argmodelpath = Path(args.modelpath)
    if args.auto_download:
        if nomodelpath:
            argmodelpath = './models/'
        logging.info(f"ğŸ“ ä¸‹è½½ç›®å½•: {argmodelpath}")
    
    if args.model == 'nllb':
        logging.info(f"ğŸŒ æºè¯­è¨€: {args.source_lang}")
        logging.info(f"ğŸŒ ç›®æ ‡è¯­è¨€: {args.target_lang}")
    
    try:
        # åŠ è½½æ¨¡å‹
        tokenizer, model = load_model(args.model, argmodelpath, args.auto_download)
        
        logging.info("ğŸ“– æ­£åœ¨è§£æSRTæ–‡ä»¶...")
        subtitles = parse_srt_file(input_path)
        logging.info(f"âœ… è§£æå®Œæˆï¼Œå…±æ‰¾åˆ° {len(subtitles)} æ¡å­—å¹•")
        
        # ç¿»è¯‘å­—å¹•
        if args.model == 'opus':
            translated_count, elapsed_time = translate_subtitles(
                subtitles, model_instance, tokenizer, model, 
                max_length=args.max_length
            )
        else:  # nllb
            translated_count, elapsed_time = translate_subtitles(
                subtitles, model_instance, tokenizer, model,
                source_lang=args.source_lang,
                target_lang=args.target_lang,
                max_length=args.max_length
            )
        
        logging.info("ğŸ’¾ æ­£åœ¨ä¿å­˜ç¿»è¯‘åçš„æ–‡ä»¶...")
        write_srt_file(subtitles, output_path)
        logging.info(f"âœ… æ–‡ä»¶ä¿å­˜æˆåŠŸ: {output_path}")
        
        logging.info(f"ğŸ‰ ç¿»è¯‘å®Œæˆï¼è¾“å‡ºæ–‡ä»¶: {output_path}")
        logging.info("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        logging.info(f"   - æ€»å­—å¹•è¡Œæ•°: {len(subtitles)}")
        logging.info(f"   - ç¿»è¯‘æˆåŠŸè¡Œæ•°: {translated_count}")
        logging.info(f"   - æ€»è€—æ—¶: {elapsed_time:.2f} ç§’")
        logging.info(f"   - å¹³å‡é€Ÿåº¦: {len(subtitles)/elapsed_time:.2f} æ¡/ç§’")
    except Exception as e:
        logging.info(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")
        sys.exit(1)

if __name__ == "__main__":
    logging.basicConfig(
        level=logging.DEBUG,
        format='%(asctime)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    logging.info("Starting JuSubTitleAutoTranslate...")
    main()
